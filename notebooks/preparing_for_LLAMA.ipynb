{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import numpy as np\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LOADING DATA\n",
    "\n",
    "dataset = 'assembly'\n",
    "\n",
    "def open_mapping(path):\n",
    "    with open(path, 'r') as f:\n",
    "        mapping = f.readlines()\n",
    "    mapping = [x.strip() for x in mapping] \n",
    "    mapping = [x.split(' ') for x in mapping]\n",
    "    mapping = [[int(x[0]), x[1]] for x in mapping]\n",
    "    mapping = [' '.join((str(x[0]),x[1])) for x in mapping]\n",
    "    return mapping\n",
    "    \n",
    "    \n",
    "if dataset == 'assembly':\n",
    "    mistake_path = '/home/aleflabo/ego_procedural/CVPR22-POC/dataset/Assembly/mistake-annotations/mistake_labels'\n",
    "    # path_to_pickles = '/home/aleflabo/ego_procedural/OadTR/models/en_3_decoder_5_lr_drop_1/results/'\n",
    "    # path_to_pickles = '/home/aleflabo/ego_procedural/OadTR/models/edo_model/models/cls_ant/results/'\n",
    "    # path_to_pickles = '/media/hdd/luca_s/egoProcel_mistakes/data_test/enc_only_text_token_mean_144/'\n",
    "    # path_to_pickles = '/media/hdd/usr/leo/egoProcel_mistakes/data_test/encoder_only-baseline/'\n",
    "    path_to_pickles = '/home/aleflabo/ego_procedural/OadTR/models/onlyThis_train+val_en_3_decoder_5_lr_drop_1_512/results/' # Leo's checkpoint\n",
    "    with open('/home/aleflabo/ego_procedural/OadTR/data/assembly/OadTR_assembly/train+val_cutGT_onlyThis/assembly_test_anno.pickle', 'rb') as outfile:\n",
    "        test_files_gt = pickle.load(outfile)\n",
    "\n",
    "    mapping_path = '/home/aleflabo/ego_procedural/OadTR/data/assembly/OadTR_assembly/train+val_cutGT_onlyThis/mapping_noBG_trimmed.txt'\n",
    "    mapping = open_mapping(mapping_path)\n",
    "    \n",
    "elif dataset == 'epicTents':\n",
    "    path_to_pickles = '/home/aleflabo/ego_procedural/OadTR/models/epicTents/en_3_decoder_5_lr_dr_solved/results/'\n",
    "    mistake_path = '/home/aleflabo/ego_procedural/OadTR/data/EpicTents/adapted_annotations/mistake_annotations'\n",
    "    with open('/home/aleflabo/ego_procedural/OadTR/data/EpicTents/OadTR/epicTents_test_anno.pickle', 'rb') as outfile:\n",
    "        test_files_gt = pickle.load(outfile)\n",
    "        \n",
    "    mapping_path = '/home/aleflabo/ego_procedural/OadTR/data/EpicTents/OadTR/mapping.txt'\n",
    "    mapping = open_mapping(mapping_path)\n",
    "\n",
    "\n",
    "# loading end frame of the window I'm looking at video\n",
    "with open(path_to_pickles+'end_frame.pickle', 'rb') as f:\n",
    "    end = pickle.load(f)\n",
    "# loading start frame of the window I'm looking at video\n",
    "with open(path_to_pickles+'start_frame.pickle', 'rb') as f:\n",
    "    start = pickle.load(f)\n",
    "# loading video names associated to the frames\n",
    "with open(path_to_pickles+'video_names_test.pickle', 'rb') as f:\n",
    "    video_names = pickle.load(f)\n",
    "# loading encoder embedddings after softmax\n",
    "with open(path_to_pickles+'results_enc_test.pickle', 'rb') as f:\n",
    "    res_enc = pickle.load(f)\n",
    "# # loading decoder embedddings after softmax\n",
    "# with open(path_to_pickles+'results_dec_test_7.pickle', 'rb') as f:\n",
    "#     res_dec = pickle.load(f)\n",
    "\n",
    "start = np.array(start)\n",
    "end = np.array(end)\n",
    "res_enc = np.asarray(res_enc).T\n",
    "# res_dec = np.asarray(res_dec['probs'])\n",
    "# res_enc = np.asarray(all_probs[\"cls\"]).T\n",
    "# res_dec = np.asarray(all_probs[\"ant\"]).T\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def take_most_frequent(actual, attention_pred):\n",
    "    # actual = seg_preds[indices]\n",
    "    temp = np.zeros_like(actual)\n",
    "    window = 200\n",
    "    for start in range(0, actual.shape[0], window):\n",
    "        \n",
    "        end = start+window\n",
    "\n",
    "        # counts = np.bincount(actual[start:end])\n",
    "        counts = np.bincount(attention_pred[start:end].reshape(-1))\n",
    "        temp[start:end] = np.argmax(counts)\n",
    "    return temp\n",
    "\n",
    "def compute_durations(label_list):\n",
    "    durations = []\n",
    "    actual = label_list[0]\n",
    "    count = 0\n",
    "    length = 0\n",
    "    for label in label_list:\n",
    "        if label == actual:\n",
    "            count += 1\n",
    "        else:\n",
    "            durations.append((actual, count))\n",
    "            length += count\n",
    "            count = 1\n",
    "            actual = label\n",
    "    durations.append((int(actual), int(count)))\n",
    "    length += count\n",
    "    print(length)\n",
    "\n",
    "    return durations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# preparing json for Edo\n",
    "dict_for_edo = {}\n",
    "for video in set(video_names):\n",
    "    print(video)\n",
    "    indices = np.where(np.array(video_names) == video)[0]\n",
    "    repeat = False\n",
    "    if repeat:\n",
    "        res = torch.tensor(res_enc.T[indices]).repeat_interleave(5, axis=0).numpy()\n",
    "    else:\n",
    "        res = res_enc.T[indices]\n",
    "    attention_pred = np.argsort(res, axis=1)[:, -1:]\n",
    "    seg_preds = torch.softmax(torch.tensor(res).permute(1,0), dim=0).argmax(0).numpy()\n",
    "    gt_durations = compute_durations(torch.softmax(torch.tensor(test_files_gt[video]['anno']).permute(1,0), dim=0).argmax(0).numpy())\n",
    "    pred_durations = compute_durations(take_most_frequent(seg_preds, attention_pred))\n",
    "\n",
    "    gt_durations, pred_durations\n",
    "\n",
    "    dict_for_edo[video] = {}\n",
    "    dict_for_edo[video]['gt'] = [int(x[0]) for x in gt_durations]\n",
    "    dict_for_edo[video]['pred'] =  [int(x[0]) for x in pred_durations]\n",
    "    dict_for_edo[video]['gt_durations'] = [int(x[1]) for x in gt_durations]\n",
    "    dict_for_edo[video]['pred_durations'] =  [int(x[1]) for x in pred_durations]\n",
    "\n",
    "\n",
    "# with open(path_to_pickles+'edo.json', 'w') as outfile:\n",
    "#     json.dump(dict_for_edo, outfile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "data = pickle.load(open('/media/hdd/usr/leo/MiniROAD/output_miniROAD.pickle', 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'anno': array([[0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        ...,\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.]], dtype=float32),\n",
       " 'feature_length': 2503}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['nusar-2021_action_both_9044-a08_9044_user_id_2021-02-05_154403']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "light",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
